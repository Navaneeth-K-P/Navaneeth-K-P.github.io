<!doctype html>
<html lang="en">
  <head>
    <title>Multi-Agent Robotics &mdash; Search & Rescue  </title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <meta name="description" content="">
    <meta name="keywords" content="html, css, javascript, jquery">
    <meta name="author" content="">

    <link rel="stylesheet" href="css/vendor/icomoon/style.css">
    <link rel="stylesheet" href="css/vendor/owl.carousel.min.css">
    <link rel="stylesheet" href="css/vendor/aos.css">
    <link rel="stylesheet" href="css/vendor/animate.min.css">
    <link rel="stylesheet" href="css/vendor/bootstrap.min.css">
    <link rel="stylesheet" href="css/vendor/jquery.fancybox.min.css">
    

    <!-- Theme Style -->
    <link rel="stylesheet" href="css/style.css">

  </head>
  <body data-spy="scroll" data-target=".site-nav-target" data-offset="200">

    <nav class="unslate_co--site-mobile-menu">
      <div class="close-wrap d-flex">
        <a href="#" class="d-flex ml-auto js-menu-toggle">
          <span class="close-label">Close</span>
          <div class="close-times">
            <span class="bar1"></span>
            <span class="bar2"></span>
          </div>
        </a>
      </div>
      <div class="site-mobile-inner"></div>
    </nav>


    <div class="unslate_co--site-wrap">

      <div class="unslate_co--site-inner">

        <div class="lines-wrap">
          <div class="lines-inner">
            <div class="lines"></div>
          </div>
        </div>
        <!-- END lines -->
      
      <nav class="unslate_co--site-nav site-nav-target">

        <div class="container">
        
          <div class="row align-items-center justify-content-between text-left">
            <div class="col-md-5 text-right">
              <ul class="site-nav-ul js-clone-nav text-left d-none d-lg-inline-block">
                
              
              </ul>
            </div>
            <div class="col-md-5 text-right text-lg-left">
              <ul class="site-nav-ul js-clone-nav text-left d-none d-lg-inline-block">
                <li class="has-children">
                  <a href="index.html#home-section" class="nav-link">Home</a>
                </li>
                <li><a href="index.html#about-section" class="nav-link">About</a></li>
                <li><a href="index.html#projects-section" class="nav-link">Projects</a></li>
                <li><a href="index.html#portfolio-section" class="nav-link">Portfolio</a></li>
                
                
                <li><a href="index.html#journal-section" class="nav-link">Blog</a></li>
                <li><a href="index.html#contact-section" class="nav-link">Contact</a></li>
              </ul>

              <ul class="site-nav-ul-none-onepage text-right d-inline-block d-lg-none">
                <li><a href="#" class="js-menu-toggle">Menu</a></li>
              </ul>

            </div>
          </div>
        </div>

      </nav>
      <!-- END nav -->

      <div class="cover-v1 jarallax overlay" style="background-image: url('images/drone.png');">
        <div class="container">
          <div class="row align-items-center">
              
            <div class="col-md-8 mx-auto text-center">
              <h1 class="blog-heading" data-aos="fade-up" data-aos-delay="0">Multi-Agent Robotics</h1>
              <div class="post-meta" data-aos="fade-up" data-aos-delay="100">Summer, 2021 &bullet; Project Log</div>
            </div>

          </div>
        </div>


        <!-- dov -->
        <a href="#blog-single-section" class="mouse-wrap smoothscroll">
          <span class="mouse">
            <span class="scroll"></span>
          </span>
          <span class="mouse-label">Scroll</span>
        </a>

      </div>
      <!-- END .cover-v1 -->

      <div class="unslate_co--section" id="blog-single-section">
        <div class="container">
          <div class="row justify-content-center">
            <div class="col-md-7">
              <h3 class="mb-4">A very different experience</h3>
              <p>Having missed out on my last research internship due to covid, I was very persistent in making sure that I make up for that loss. This was crucial now that I was 100% sure that research and higher studies are my priority. Throughout the academic year, I pushed myself to learn as much as possible and complete most of my degree by the end of the third year. I successfully did so and am left with only one core course and a specialization project to complete my degree and specialization in robotics. Now that I was almost done with that, the next goal was to work on good projects. DSL810 and the MasterCard design challenge turned out to be two great projects I am proud of, but it was not related to Robotics.</p>
              <br>
              <p>With all this being the situation and the pandemic not showing any signs of vanishing, I decided to try for a good online internship and prep for GRE in the comfort of my home. I had been looking out for professors working on domains I found fascinating. However, there was one team that had my attention since last year,  <a href="https://www.marmotlab.org/">Marmot Lab (NUS)</a> . The lab focused on Multi-Agent robotics which was one of the domains I was looking forward to exploring. I had heard a lot about them from Priyanshi, who interned with them last summer. I ended up contacting Prof.Guillaume, who responded positively and welcomed me onboard. The meetings with the team were very much different from what I had expected. Like Jay sir, he was also keen on his students coming up with their research ideas and projects. The meetings were similar to a chat between a bunch of colleagues, a very stress-free but, at the same time, very productive environment. Since I had chosen to work on Multi-agent search (over hexapod robots, which would have been more involved with what I learned in JRL302 and MCL745 and more kinematics intensive), I had limited knowledge about what was being discussed. Still, with the help of google on the side, I was able to figure out a good part of it. Even though some of my friends were confused about my choice of MA search over Hexapod, I was very much interested in learning the new domain. The resources provided by Prof. were beneficial in catching the basics.</p>
              <br>
              <h3 class="mb-4">Project Proposal</h3>
              <p>As I mentioned earlier, just like Jay sir, Prof.Guillaume also expected his students to develop their project proposals. Along with learning the new domain, I was also going through the research by the team. My initial idea was to look at something along the lines of mapping inspired by their current MA Search. However, after discussions with the team, I realized that it was not as connected to MA Search as I thought it was. However, I found another idea that came up in the meeting quite fascinating. It was linked to multi-agents with some form of consumable resource in it. Prof.Guillaume also asked me to go through ForMIC, a previous project of his for some more inspiration. After a thorough analysis of the paper and motivation from the meeting discussions, I came up with the following proposal, which Prof. found interesting and encouraged me to work on.</p>

              <p><a href="https://drive.google.com/file/d/1oKANcx6W_OGqYpHrw3LKpoPHQPz__ssZ/view?usp=sharing" target="_blank"><img src="images/proposal_drone.png" alt="Image" class="img-fluid" ><br> Click this image for complete presentation.</a></p>
             
              <p>After finalizing my project, I started working on implementing it. Brushing up on the Neural network knowledge from last summer and also exploring the existing ForMIC code. The project is very intersting and I have decided to stick to it untill I complete it and maybe even after that.</p>
              <br>
              <br>
              <h3 class="mb-4">Maze Solver using Q-Table</h3>
              <p>This program solves the Open Ai gym maze environment using Q-Tables to find the shortest path from start to finish using Q-Table. The program works for all the different mazes available in the library. The algorithm used follows the Bellman's Equation to create the Q table. After learning, the Q-table is directly used to make decisions in the simulation phase to find the best action at a particular state. The maze environment used is <a href="https://github.com/MattChanTK/gym-maze/">available here</a> . The project repository is <a href="https://github.com/Navaneeth-K-P/Maze-Solver">Maze-Solver<a> . This project helped me implement my learnings on Q-table and also apply the concepts to real life applications.</p>
              <br>
              <br>
              <h3 class="mb-4">Actor Critic Model</h3>
              <p>As mentioned earlier, the learning time for my neural network was very high. Hence, I decided to implement an A3C model (Asynchronous Actor Crytic model) which has the capability to learn faster. I had a hard time understanding the implement even though the basic idea was straight forward. This blog was a very good read (<a href="https://medium.com/@shagunm1210/implementing-the-a3c-algorithm-to-train-an-agent-to-play-breakout-c0b5ce3b3405">link</a>)</p>. 
              <a href="https://youtu.be/6_XT8o9wiwU" class="portfolio-item isotope-item gsap-reveal-img" data-fancybox="gallery" data-caption="Maze Solver">
                <div class="overlay">
                  <div class="portfolio-item-content">
                    <h3>Maze Solver</h3>
                    <p class="post-meta">Simulation</p>
                  </div>
                </div>
                <img src="images/tmbnl.png" class="lazyload  img-fluid" alt="Images" />
              </a>
              <br>
              <br>
              <h3 class="mb-4">Maze Solver using Neural Networks</h3>
              <p>Having taken my neural network course a year ago, I really needed to brush up on it. This playlist is a good revision modules for Neural Networks (<a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">link<a>). For a quick guide on the different types of neural networks, this blog will be useful (<a href="https://www.digitalvidya.com/blog/types-of-neural-networks/">link<a>). Using the same environment as int he Q-learning model, I was able to implement an agent using neural network for generating Q values for each state. The learning process took more time (almost 1 hr) in agent using Neural network since it is more computationally exhaustive and I am running this on my PC. However, they gave the desired results for similar mazes within comparable episodes. The project repository is <a href="https://github.com/Navaneeth-K-P/Maze-Solver-NN">Maze-Solver-NN<a>. My project will require both CNNs and LSTM networks. This blog was helpful in easily understanding CNNs (<a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">link<a>). For understanding LSTM networks, this blog was helpful (<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">link</a>). The more I dive into RL and Neural networks, the more interesting it gets. The digitalization of the fundamental workings of the human brain is indeed an amazing feat. Also day by day Bellman's equation looks more and more elegant. A single equation that forms the backbone of RL.</p>
              <br>
              <br>
              <h3>Incorporating the central control tower</h3>
              <p>In my project proposal, I had proposed a system that would relay the location of a target to the nearby agents in case where the agent that first encountered the target was not able to completely exhaust the target (can be due to fuel or storage related constraints). These messages can be used in the decision making process of each agent. I relize that this can be incorporated in such a way that if an agent recieves such a message, instead of the random exploration it will choose to move along this direction with proability that is proportional to the distance to the target (since if it recieves a message that the target is very close, there should be a higher probability that it chooses to move towards it). I guess I will need two cases where an agent with no message will utilise the e-greedy approach and the one with the message will choose between the direction from the neural network vs the direction suggested by the neural network. However, I feel like the message should also be an input of the neural network. The proposed structure of my network is as given below.</p>
              <p><a href="https://miro.com/app/board/o9J_lBHxAmI=/"><img src="images/nn.png" alt="Image" class="img-fluid" ><br>Click to view my mind map and progress</a></p>
              <br>
              <p>For learning phase of the agent, the following strategy is suggested. This is based on the general understanding that an agent which dooes not have a target in its field of view will choose to move towards a potential target location that is provided by the message, rather than choosing to move randomly.</p>
              
              <p>Finally, the learning process is also modified to incorporate the messages that will be involved. The proposed strategy is given below.</p>
              <br>
              <h3>Possible Decentralization?</h3>
              <p>While in the meeting, I was struck with the idea that instead of a command centre, what if the agents themselves broadcasted the messages. This was inspired by the copying of maps in agents for the masearch implementation. This could possibly decentralize the whole process and also it also incorporates a range for the message which will prevent the message being recieved by agents which are very far away. The whole thing looks complicated in execution but will make the whole simulation more effective and lifelike. Such an implementation, I believe, will require a message stack also with the agent recieving multiple messages at a time instant. This is not required in a command center model as the tower will transmit only one message at a time.</p>
              <div class="post-single-navigation d-flex align-items-stretch">
                
                <a href="dsl810.html" class="ml-auto w-50 text-right pl-4">
                  <span class="d-block">Next Post</span>
                  DSL810: Corona Prediction & Vaccine supply
                </a>
              </div>


            
              <!-- END comment-list -->
              
              
            </div>
            </div>
          </div>
        </div>
      </div>

      
      </div> 

      <footer class="unslate_co--footer unslate_co--section">
        <div class="container">
          <div class="row justify-content-center">
            <div class="col-md-7">
              
              <div class="footer-site-logo"><a href="#">Navaneeth K P<span>.</span></a></div>

              <ul class="footer-site-social">
                <li><a href="https://www.facebook.com/navaneeth.kp.50/" target="_blank">Facebook</a></li>
                <li><a href="https://twitter.com/NavaneethKP20" target="_blank">Twitter</a></li>
                <li><a href="https://www.instagram.com/navaneeth_k_p/" target="_blank">Instagram</a></li>
                
              </ul>

              <p class="site-copyright">
                
                <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                Copyright &copy;
                <script>
                  document.write(new Date().getFullYear());
                </script> All rights reserved | This template is made with <i class="icon-heart"
                  aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
                <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
              
              </p>

            </div>
          </div>
        </div>
      </footer>

      
    </div>

    <!-- Loader -->
    <div id="unslate_co--overlayer"></div>
    <div class="site-loader-wrap">
      <div class="site-loader"></div>
    </div>

    <script src="js/scripts-dist.js"></script>
    <script src="js/main.js"></script>

  </body>
</html>
